{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4687ab22",
   "metadata": {},
   "source": [
    "# PersonalRAG\n",
    "\n",
    "A streamlined RAG system for your personal documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064630e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "# PDF processing\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51963c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete RAG System Setup\n",
    "# =========================\n",
    "\n",
    "# Configuration\n",
    "MODEL = 'gpt-5-nano'\n",
    "db_name = 'vector_db'\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Validate environment\n",
    "required_vars = [\n",
    "    'AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_API_KEY',\n",
    "    'AZURE_OPENAI_API_VERSION',\n",
    "    'AZURE_OPENAI_EMBEDDING_DEPLOYMENT',\n",
    "\n",
    "\n",
    "    'AZURE_CHATOPENAI_DEPLOYMENT',\n",
    "    'AZURE_CHATOPENAI_ENDPOINT', 'AZURE_CHATOPENAI_API_KEY',\n",
    "    'AZURE_CHATOPENAI_API_VERSION'\n",
    "]\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing: {missing}\")\n",
    "    env_ok = False\n",
    "else:\n",
    "    print(\"‚úÖ Environment OK\")\n",
    "    env_ok = True\n",
    "\n",
    "# Initialize embeddings and LLM\n",
    "if env_ok:\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    )\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.getenv('AZURE_CHATOPENAI_DEPLOYMENT'),\n",
    "        azure_endpoint=os.getenv('AZURE_CHATOPENAI_ENDPOINT'),\n",
    "        api_key=os.getenv('AZURE_CHATOPENAI_API_KEY'),\n",
    "        api_version=os.getenv('AZURE_CHATOPENAI_API_VERSION'),\n",
    "    )\n",
    "    print(\"‚úÖ Embeddings and LLM initialized\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize - check environment variables\")\n",
    "    embeddings = None\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbddcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Process Documents\n",
    "# ==========================\n",
    "\n",
    "# Check PDF processing availability\n",
    "try:\n",
    "    import pdfplumber\n",
    "    PDF_AVAILABLE = True\n",
    "    print(\"‚úÖ PDF processing available (pdfplumber)\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        PDF_AVAILABLE = True\n",
    "        print(\"‚úÖ PDF processing available (PyPDF2)\")\n",
    "    except ImportError:\n",
    "        PDF_AVAILABLE = False\n",
    "        print(\"‚ö†Ô∏è PDF processing not available - install pdfplumber or PyPDF2\")\n",
    "\n",
    "# Auto-convert PDFs to markdown\n",
    "for root, dirs, files in os.walk(\"my-knowledge-worker-data\"):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(root, file)\n",
    "            md_path = pdf_path.rsplit('.', 1)[0] + '.md'\n",
    "\n",
    "            if not os.path.exists(md_path):\n",
    "                try:\n",
    "                    with pdfplumber.open(pdf_path) as pdf:\n",
    "                        text = \"\\n\\n\".join(\n",
    "                            [p.extract_text() or \"\" for p in pdf.pages])\n",
    "                    if text.strip():\n",
    "                        with open(md_path, 'w', encoding='utf-8') as f:\n",
    "                            f.write(f\"# {os.path.splitext(file)[0]}\\n\\n{text}\")\n",
    "                        print(f\"‚úÖ Converted: {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error: {file} - {e}\")\n",
    "\n",
    "\n",
    "def load_all_documents():\n",
    "    \"\"\"Load all markdown files from my-knowledge-worker-data\"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for folder in glob.glob(\"my-knowledge-worker-data/*\"):\n",
    "        doc_type = os.path.basename(folder)\n",
    "        loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "        folder_docs = loader.load()\n",
    "\n",
    "        for doc in folder_docs:\n",
    "            doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.extend(folder_docs)\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Load documents\n",
    "documents = load_all_documents()\n",
    "print(f\"üìÑ Loaded {len(documents)} documents\")\n",
    "\n",
    "# Improved chunking for better retrieval of resume sections (especially EDUCATION)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,  # smaller chunks to keep section details together\n",
    "    chunk_overlap=120,  # overlap for context retention and continuity\n",
    "    # prioritize splitting on section, line, and sentence boundaries\n",
    "    separators=[\"\\n## \", \"\\n# \", \"\\n- \", \"\\n\", \". \"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"üìù Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always delete and recreate database for fresh start\n",
    "# ===================================================\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Force delete existing database\n",
    "if os.path.exists(db_name):\n",
    "    shutil.rmtree(db_name)\n",
    "    print(f\"üóëÔ∏è Deleted existing database: {db_name}\")\n",
    "\n",
    "# Always create fresh vector database\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=db_name\n",
    ")\n",
    "print(\n",
    "    f\"‚úÖ Created fresh database ({vectorstore._collection.count()} documents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector database if needed\n",
    "if vectorstore is None:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_name\n",
    "    )\n",
    "    print(\n",
    "        f\"‚úÖ Created new database ({vectorstore._collection.count()} documents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34527063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Settings\n",
    "from datetime import datetime\n",
    "import os\n",
    "MODEL = 'gpt-5-nano'\n",
    "\n",
    "# Vector Database Configuration\n",
    "\n",
    "# Option 1: Simple name (current approach)\n",
    "db_name = 'vector_db'\n",
    "\n",
    "# Option 2: Timestamped database (uncomment to use)\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# db_name = f'vector_db_{timestamp}'\n",
    "\n",
    "# Option 3: Environment variable with fallback (uncomment to use)\n",
    "# db_name = os.getenv('VECTOR_DB_NAME', 'vector_db')\n",
    "\n",
    "# Option 4: Full path configuration (uncomment to use)\n",
    "# db_name = os.path.join('data', 'vector_databases', 'personal_knowledge_db')\n",
    "\n",
    "print(f\"Vector database will be stored as: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf44f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"my-knowledge-worker-data/*\")\n",
    "\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "    # Adds a 'doc_type' field to the document's metadata and returns the modified document\n",
    "\n",
    "\n",
    "text_loader_kwargs = {\"encoding\": \"utf-8\"}\n",
    "\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(\n",
    "        folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    temp_docs = loader.load()\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "# Improved chunking for better retrieval of resume sections (especially EDUCATION)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,  # smaller chunks to keep section details together\n",
    "    chunk_overlap=120,  # overlap for context retention and continuity\n",
    "    # prioritize splitting on section, line, and sentence boundaries\n",
    "    separators=[\"\\n## \", \"\\n# \", \"\\n- \", \"\\n\", \". \"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9416245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Document types found: {set([doc.metadata['doc_type'] for doc in documents])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternative Embeddings Options\n",
    "# ================================\n",
    "\n",
    "# you can use these alternatives:\n",
    "\n",
    "# Option 1: HuggingFace Embeddings (Free, Local)\n",
    "# Uncomment the lines below to use HuggingFace embeddings instead:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# Option 2: OpenAI Embeddings (if you have OpenAI API key)\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=\"your-openai-api-key\")\n",
    "\n",
    "# Option 3: Azure OpenAI Embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "# Usage Instructions:\n",
    "# 1. If Azure OpenAI embeddings failed, uncomment the HuggingFace lines above\n",
    "# 2. Or call: embeddings = get_alternative_embeddings()\n",
    "# 3. Make sure to install: pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b2b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "try:\n",
    "    # Check if collection has any embeddings\n",
    "    count = collection.count()\n",
    "    if count > 0:\n",
    "        sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\n",
    "            \"embeddings\"][0]\n",
    "        dimensions = len(sample_embedding)\n",
    "        print(f\"The vectors have {dimensions:,} dimensions\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No embeddings found in the collection. Run the rebuild cell first.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error accessing embeddings: {e}\")\n",
    "    print(\"üí° Make sure to run the rebuild cell (Cell 20) first to create the vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42fc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e929534",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 35})\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb559481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Prompt Template for Better Responses\n",
    "# ===========================================\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"  \n",
    "    \n",
    "# IDENTITY & PURPOSE\n",
    "You are a Personal AI Assistant specialized in answering questions about the user's professional profile, educational background, work experience, projects, and skills. You function as an intelligent retrieval interface over the user's personal knowledge base.\n",
    "\n",
    "# KNOWLEDGE SOURCE\n",
    "- Primary Source: User's personal documents (resumes, records, portfolios)\n",
    "- Access Method: Semantic search retrieval on vector database\n",
    "- Update Frequency: Documents are current as of user's last update\n",
    "- Scope Limitation: You answer ONLY from retrieved context, never from general knowledge\n",
    "\n",
    "# OPERATIONAL CONSTRAINTS\n",
    "\n",
    "## Constraint 1: Grounding Requirement\n",
    "Answer exclusively from the provided context. Apply these rules:\n",
    "- ‚úì DO: Extract and present facts directly from context\n",
    "- ‚úì DO: Combine information from multiple context chunks when relevant\n",
    "- ‚úó DON'T: Use external knowledge or training data\n",
    "- ‚úó DON'T: Infer or extrapolate beyond stated facts\n",
    "- ‚úó DON'T: Make assumptions about unstated information\n",
    "\n",
    "## Constraint 2: Response Protocol\n",
    "When information is missing or unclear:\n",
    "- If zero relevant information: \"I don't have that information in your documents\"\n",
    "- If partial information: State what exists + acknowledge what's missing\n",
    "- If outdated possibility: Present available info + suggest user may want to update documents\n",
    "\n",
    "## Constraint 3: No Hallucination Policy\n",
    "If you're unsure or the context is ambiguous:\n",
    "- Default to \"information not found\" rather than guessing\n",
    "- Never fabricate dates, numbers, names, or details\n",
    "- Never blend context facts with general assumptions\n",
    "\n",
    "# COMMUNICATION STYLE\n",
    "\n",
    "## Tone: Conversational & Personal\n",
    "- Use second-person: \"You worked at...\", \"Your degree in...\", \"You have experience with...\"\n",
    "- Sound like a helpful colleague reviewing documents together\n",
    "- Be warm but professional\n",
    "- Avoid robotic phrases: \"As an AI\", \"I cannot\", \"I'm unable to\"\n",
    "\n",
    "## Structure: Clear & Scannable\n",
    "- Single facts: Complete sentences with full detail\n",
    "- Multiple items: Bullet points with parallel structure\n",
    "- Dates: Use consistent format (MM/YYYY or Year)\n",
    "- Lists: Most recent first (unless chronological narrative requested)\n",
    "\n",
    "## Detail Level: Comprehensive & Specific\n",
    "Always include when available:\n",
    "- Education: [Institution] - [Degree/Program] - [Year/Duration] - [Grade/Percentage/CGPA]\n",
    "- Work: [Company] - [Role] - [Duration] - [Key Achievements/Responsibilities]\n",
    "- Projects: [Name] - [Technologies] - [Description] - [Your Role/Contribution]\n",
    "- Skills: [Technology/Tool] - [Experience Level/Years] - [Context of Use]\n",
    "\n",
    "# QUERY CLASSIFICATION & RESPONSE PATTERNS\n",
    "\n",
    "## Type 1: Factual Lookup\n",
    "User asks for specific fact (date, grade, company name)\n",
    "‚Üí Provide direct answer with full context\n",
    "Example: \"You graduated in May 2018 with a B.Tech in Computer Science from ABC University with an 8.5 CGPA.\"\n",
    "\n",
    "## Type 2: List Queries\n",
    "User asks \"what skills/projects/jobs...\"\n",
    "‚Üí Bullet-pointed list with details for each item\n",
    "Example: \"Your web development skills include:\n",
    "‚Ä¢ Frontend: React, Vue.js, HTML5/CSS3 - 3 years professional experience\n",
    "‚Ä¢ Backend: Node.js, Express, Django - used in 5+ production projects\n",
    "‚Ä¢ Databases: MongoDB, PostgreSQL - managed databases handling 1M+ records\"\n",
    "\n",
    "## Type 3: Summaries\n",
    "User asks for overview/summary of section\n",
    "‚Üí Organized breakdown by category with key highlights\n",
    "Example: \"Here's your professional summary:\n",
    "\n",
    "**Current Role:** Senior Developer at TechCorp (2021-Present)\n",
    "**Experience:** 5 years in software development\n",
    "**Education:** M.S. Computer Science, XYZ University (2019)\n",
    "**Specialization:** Full-stack development, Cloud architecture, Machine Learning\n",
    "**Key Achievement:** Led development of ML platform serving 100K+ users\"\n",
    "\n",
    "## Type 4: Comparisons\n",
    "User asks to compare two things\n",
    "‚Üí Side-by-side structured comparison\n",
    "Example: \"Comparing your education levels:\n",
    "\n",
    "**Undergraduate (2014-2018):**\n",
    "‚Ä¢ Institution: ABC College\n",
    "‚Ä¢ Degree: B.Tech Computer Science\n",
    "‚Ä¢ Performance: 8.5/10 CGPA\n",
    "‚Ä¢ Key Courses: Data Structures, Algorithms, Databases\n",
    "\n",
    "**Graduate (2018-2019):**\n",
    "‚Ä¢ Institution: XYZ University  \n",
    "‚Ä¢ Degree: M.S. Computer Science\n",
    "‚Ä¢ Performance: 3.8/4.0 GPA\n",
    "‚Ä¢ Specialization: Machine Learning, Deep Learning\"\n",
    "\n",
    "## Type 5: Timeline/History\n",
    "User asks about progression or \"when did I...\"\n",
    "‚Üí Chronological narrative or timeline\n",
    "Example: \"Your career progression:\n",
    "‚Ä¢ 2019-2020: Junior Developer at StartupCo - building microservices\n",
    "‚Ä¢ 2020-2021: Software Engineer at MidSizeTech - full-stack development\n",
    "‚Ä¢ 2021-Present: Senior Developer at TechCorp - leading ML initiatives\"\n",
    "\n",
    "## Type 6: Information Not Found\n",
    "Retrieved context is empty/irrelevant\n",
    "‚Üí Clear statement of unavailability\n",
    "Example: \"I don't have information about certifications in your documents.\"\n",
    "\n",
    "# CONTEXT PROCESSING INSTRUCTIONS\n",
    "\n",
    "You will receive input in this structure:\n",
    "```\n",
    "CONTEXT:\n",
    "[Retrieved document chunks - may contain multiple segments]\n",
    "\n",
    "QUERY:\n",
    "[User's question]\n",
    "```\n",
    "\n",
    "Processing Steps:\n",
    "1. Read all context chunks thoroughly\n",
    "2. Identify which chunks are relevant to the query\n",
    "3. Extract all pertinent facts from relevant chunks\n",
    "4. Synthesize into coherent response following the appropriate pattern\n",
    "5. Verify response contains only context-grounded information\n",
    "6. Format according to query type\n",
    "\n",
    "# EXAMPLES OF COMPLETE INTERACTIONS\n",
    "\n",
    "**Example 1: Direct Fact**\n",
    "Context: \"John completed B.Tech in Computer Science from Delhi University in 2018 with 85%\"\n",
    "Query: \"What was my graduation percentage?\"\n",
    "Response: \"Your B.Tech graduation percentage was 85%, which you completed from Delhi University in 2018.\"\n",
    "\n",
    "**Example 2: Skills List**\n",
    "Context: \"Proficient in Python (Django, Flask), JavaScript (React, Node.js), worked with AWS and Docker\"\n",
    "Query: \"What technical skills do I have?\"\n",
    "Response: \"Your technical skills include:\n",
    "‚Ä¢ Python: Django and Flask frameworks\n",
    "‚Ä¢ JavaScript: React for frontend, Node.js for backend\n",
    "‚Ä¢ Cloud: AWS\n",
    "‚Ä¢ DevOps: Docker\"\n",
    "\n",
    "**Example 3: Missing Info**\n",
    "Context: \"Worked at TechCorp as Software Engineer from 2020-2022\"\n",
    "Query: \"What was my starting salary?\"\n",
    "Response: \"I don't have information about your starting salary in your documents.\"\n",
    "\n",
    "**Example 4: Work Summary**\n",
    "Context: \"Software Engineer at TechCorp (2020-2022): Developed ML pipelines, mentored 3 junior developers, increased system performance by 40%\"\n",
    "Query: \"Tell me about my TechCorp role\"\n",
    "Response: \"You worked as a Software Engineer at TechCorp from 2020 to 2022. Your key contributions included:\n",
    "‚Ä¢ Developing ML pipelines\n",
    "‚Ä¢ Mentoring 3 junior developers\n",
    "‚Ä¢ Improving system performance by 40%\"\n",
    "\n",
    "# QUALITY CHECKS BEFORE RESPONDING\n",
    "Before sending each response, verify:\n",
    "- ‚úì All facts are from provided context\n",
    "- ‚úì Used \"You/Your\" perspective\n",
    "- ‚úì Included specific details (dates, numbers, names)\n",
    "- ‚úì Format matches query type\n",
    "- ‚úì No assumptions or external knowledge used\n",
    "- ‚úì Conversational and helpful tone\n",
    "- ‚úì No AI-centric language\n",
    "\n",
    "Now, answer the user's query using only the retrieved context provided.\n",
    "\n",
    "Context: {context}\n",
    "Chat History: {chat_history}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"chat_history\", \"question\"]\n",
    ")\n",
    "\n",
    "# Update the conversation chain with the custom prompt\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": qa_prompt}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Custom prompt template applied to conversation chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151377ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"what is my work experience\"\n",
    "# result = conversation_chain.invoke({\"question\": query})\n",
    "# answer = result[\"answer\"]\n",
    "# print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc902a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_greeting(message):\n",
    "    \"\"\"Check if the message is a greeting\"\"\"\n",
    "    greetings = [\n",
    "        'hi', 'hello', 'hey', 'good morning', 'good afternoon', 'good evening',\n",
    "        'greetings', 'howdy', 'sup', 'what\\'s up', 'yo', 'good day',\n",
    "        'hi there', 'hello there', 'hey there', 'good to see you'\n",
    "    ]\n",
    "\n",
    "    message_lower = message.lower().strip()\n",
    "\n",
    "    # Check for exact matches\n",
    "    if message_lower in greetings:\n",
    "        return True\n",
    "\n",
    "    # Check if message starts with greeting\n",
    "    for greeting in greetings:\n",
    "        if message_lower.startswith(greeting):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_greeting_response():\n",
    "    \"\"\"Get a friendly greeting response\"\"\"\n",
    "    greetings = [\n",
    "        \"Hello! üëã I'm PersonalRAG, your AI knowledge assistant. I'm here to help you find information from your documents, projects, and work experience. What would you like to know?\",\n",
    "        \"Hi there! ü§ñ Welcome to PersonalRAG. I can help you search through your knowledge base and answer questions about your work, projects, and documents. How can I assist you today?\",\n",
    "        \"Hey! üòä Great to see you! I'm PersonalRAG, ready to help you explore your personal knowledge base. Feel free to ask me anything about your documents or projects!\",\n",
    "        \"Hello! üåü I'm PersonalRAG, your intelligent knowledge assistant. I'm here to help you discover insights from your documents and answer questions about your work experience. What can I help you with?\"\n",
    "    ]\n",
    "\n",
    "    import random\n",
    "    return random.choice(greetings)\n",
    "\n",
    "\n",
    "def chat_messages(message, history):\n",
    "    \"\"\"Chat function that returns messages in the correct format with greeting support\"\"\"\n",
    "    try:\n",
    "        # Check for greetings first\n",
    "        if is_greeting(message):\n",
    "            greeting_response = get_greeting_response()\n",
    "            return history + [{\"role\": \"assistant\", \"content\": greeting_response}]\n",
    "\n",
    "        # Get response from conversation chain\n",
    "        result = conversation_chain.invoke({\"question\": message})\n",
    "        response = result[\"answer\"]\n",
    "\n",
    "        # Return in the correct format for messages\n",
    "        return history + [{\"role\": \"assistant\", \"content\": response}]\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Sorry, I encountered an error: {str(e)}\\n\\nPlease try again or rephrase your question.\"\n",
    "        return history + [{\"role\": \"assistant\", \"content\": error_msg}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Clean Black Theme Interface\n",
    "# ====================================\n",
    "\n",
    "# Custom CSS for clean black theme with improved textbox\n",
    "custom_css = \"\"\"\n",
    "/* Clean Black Theme */\n",
    ".gradio-container {\n",
    "    font-family: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif !important;\n",
    "    background: #000000 !important;\n",
    "    min-height: 100vh !important;\n",
    "}\n",
    "\n",
    "/* Main container styling */\n",
    ".main-container {\n",
    "    background: #111111 !important;\n",
    "    border-radius: 12px !important;\n",
    "    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5) !important;\n",
    "    border: 1px solid #333333 !important;\n",
    "}\n",
    "\n",
    "/* Header styling */\n",
    ".header {\n",
    "    background: #000000 !important;\n",
    "    color: #ffffff !important;\n",
    "    padding: 32px !important;\n",
    "    border-radius: 12px 12px 0 0 !important;\n",
    "    text-align: center !important;\n",
    "    border-bottom: 2px solid #333333 !important;\n",
    "}\n",
    "\n",
    ".header h1 {\n",
    "    margin: 0 !important;\n",
    "    font-size: 2.5em !important;\n",
    "    font-weight: 700 !important;\n",
    "    letter-spacing: -1px !important;\n",
    "    color: #ffffff !important;\n",
    "}\n",
    "\n",
    ".header p {\n",
    "    margin: 12px 0 0 0 !important;\n",
    "    font-size: 1.1em !important;\n",
    "    opacity: 0.8 !important;\n",
    "    font-weight: 400 !important;\n",
    "    color: #cccccc !important;\n",
    "}\n",
    "\n",
    "/* Chat interface styling */\n",
    ".chat-container {\n",
    "    background: #111111 !important;\n",
    "    border-radius: 0 0 12px 12px !important;\n",
    "    padding: 24px !important;\n",
    "}\n",
    "\n",
    "/* Clean chatbot message bubbles */\n",
    ".chatbot-clean .chat-message,\n",
    ".chatbot-clean .message,\n",
    ".chatbot-clean .prose {\n",
    "    background: none !important;\n",
    "    box-shadow: none !important;\n",
    "    border: none !important;\n",
    "    margin: 8px 0 !important;\n",
    "    padding: 0 !important;\n",
    "}\n",
    "\n",
    ".chatbot-clean .user,\n",
    ".user-message {\n",
    "    background: #1a1a1a !important;\n",
    "    color: #fff !important;\n",
    "    border-radius: 14px !important;\n",
    "    padding: 12px 22px !important;\n",
    "    margin-left: auto !important;\n",
    "    margin-right: 16px !important;\n",
    "    box-shadow: 0 1px 6px rgba(0,0,0,0.18);\n",
    "    width: max-content !important;\n",
    "    min-width: 56px !important;\n",
    "    max-width: 90vw !important;\n",
    "    border: 1px solid #232323 !important;\n",
    "    font-size: 1.05em !important;\n",
    "    text-align: left !important;\n",
    "    font-family: inherit !important;\n",
    "    white-space: nowrap !important;\n",
    "    overflow-x: auto !important;\n",
    "}\n",
    "\n",
    ".chatbot-clean .assistant,\n",
    ".assistant-message {\n",
    "    background: #141414 !important;\n",
    "    color: #f2f2f2 !important;\n",
    "    border-radius: 14px !important;\n",
    "    padding: 16px 22px !important;\n",
    "    margin-right: auto !important;\n",
    "    margin-left: 8px !important;\n",
    "    box-shadow: 0 1px 6px rgba(0,0,0,0.13);\n",
    "    max-width: 75% !important;\n",
    "    border: 1px solid #232323 !important;\n",
    "    font-size: 1.05em !important;\n",
    "    font-family: inherit !important;\n",
    "}\n",
    "\n",
    "/* Remove message box styling from container */\n",
    ".message, .prose {\n",
    "    background: none !important;\n",
    "    border: none !important;\n",
    "    box-shadow: none !important;\n",
    "}\n",
    "\n",
    "\n",
    "/* Enhanced Textbox Styling */\n",
    ".input-container {\n",
    "    background: #1a1a1a !important;\n",
    "    border-radius: 12px !important;\n",
    "    padding: 0 !important;\n",
    "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.3) !important;\n",
    "    border: 2px solid #333333 !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "    position: relative !important;\n",
    "    overflow: hidden !important;\n",
    "}\n",
    "\n",
    ".input-container:focus-within {\n",
    "    border-color: #ffffff !important;\n",
    "    box-shadow: 0 0 0 3px rgba(255, 255, 255, 0.1) !important;\n",
    "    transform: translateY(-1px) !important;\n",
    "}\n",
    "\n",
    "/* Text input specific styling */\n",
    "input[type=\"text\"], textarea {\n",
    "    color: #ffffff !important;\n",
    "    background-color: transparent !important;\n",
    "    border: none !important;\n",
    "    outline: none !important;\n",
    "    padding: 14px 20px !important;\n",
    "    font-size: 16px !important;\n",
    "    line-height: 1.5 !important;\n",
    "    width: 100% !important;\n",
    "    resize: none !important;\n",
    "    font-family: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif !important;\n",
    "    height: 48px !important;\n",
    "    min-height: 48px !important;\n",
    "    max-height: 48px !important;\n",
    "}\n",
    "\n",
    "input[type=\"text\"]::placeholder, textarea::placeholder {\n",
    "    color: #888888 !important;\n",
    "    font-style: italic !important;\n",
    "    opacity: 0.8 !important;\n",
    "}\n",
    "\n",
    "input[type=\"text\"]:focus, textarea:focus {\n",
    "    outline: none !important;\n",
    "    border: none !important;\n",
    "    box-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* Button styling */\n",
    ".btn-primary {\n",
    "    background: linear-gradient(135deg, #ffffff 0%, #f0f0f0 100%) !important;\n",
    "    border: none !important;\n",
    "    border-radius: 10px !important;\n",
    "    padding: 14px 28px !important;\n",
    "    color: #000000 !important;\n",
    "    font-weight: 600 !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "    box-shadow: 0 2px 8px rgba(255, 255, 255, 0.2) !important;\n",
    "    font-size: 14px !important;\n",
    "    text-transform: uppercase !important;\n",
    "    letter-spacing: 0.5px !important;\n",
    "    height: 48px !important;\n",
    "    min-height: 48px !important;\n",
    "    max-height: 48px !important;\n",
    "}\n",
    "\n",
    ".btn-primary:hover {\n",
    "    background: linear-gradient(135deg, #f0f0f0 0%, #e0e0e0 100%) !important;\n",
    "    box-shadow: 0 4px 12px rgba(255, 255, 255, 0.3) !important;\n",
    "    transform: translateY(-2px) !important;\n",
    "}\n",
    "\n",
    ".btn-secondary {\n",
    "    background: #333333 !important;\n",
    "    border: 1px solid #555555 !important;\n",
    "    border-radius: 8px !important;\n",
    "    padding: 10px 20px !important;\n",
    "    color: #ffffff !important;\n",
    "    font-weight: 500 !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "    font-size: 13px !important;\n",
    "}\n",
    "\n",
    ".btn-secondary:hover {\n",
    "    background: #444444 !important;\n",
    "    border-color: #666666 !important;\n",
    "    transform: translateY(-1px) !important;\n",
    "}\n",
    "\n",
    "/* Chatbot styling */\n",
    ".chatbot {\n",
    "    background: #0a0a0a !important;\n",
    "    border: 1px solid #333333 !important;\n",
    "    border-radius: 12px !important;\n",
    "    padding: 20px !important;\n",
    "}\n",
    "\n",
    "/* Input row styling */\n",
    ".input-row {\n",
    "    display: flex !important;\n",
    "    gap: 12px !important;\n",
    "    align-items: flex-end !important;\n",
    "    margin-top: 20px !important;\n",
    "}\n",
    "\n",
    "/* Responsive design */\n",
    "@media (max-width: 768px) {\n",
    "    .main-container {\n",
    "        margin: 10px !important;\n",
    "        border-radius: 12px !important;\n",
    "    }\n",
    "    \n",
    "    .header h1 {\n",
    "        font-size: 2em !important;\n",
    "    }\n",
    "    \n",
    "    .user-message, .assistant-message {\n",
    "        margin-left: 5% !important;\n",
    "        margin-right: 5% !important;\n",
    "    }\n",
    "    \n",
    "    .input-container {\n",
    "        padding: 0 !important;\n",
    "    }\n",
    "    \n",
    "    input[type=\"text\"], textarea {\n",
    "        padding: 14px 16px !important;\n",
    "        font-size: 14px !important;\n",
    "    }\n",
    "    \n",
    "    .chatbot-clean .user,\n",
    ".user-message {\n",
    "    background: #1a1a1a !important;\n",
    "    color: #fff !important;\n",
    "    border-radius: 20px !important;\n",
    "    padding: 10px 20px !important;\n",
    "    margin-left: auto !important;\n",
    "    margin-right: 16px !important;\n",
    "    box-shadow: 0 1px 6px rgba(0,0,0,0.18);\n",
    "    width: max-content !important;\n",
    "    min-width: 56px !important;\n",
    "    max-width: 55vw !important;\n",
    "    border: 1px solid #232323 !important;\n",
    "    font-size: 1.08em !important;\n",
    "    text-align: left !important;\n",
    "    font-family: inherit !important;\n",
    "    word-break: break-word !important;\n",
    "    white-space: pre-line !important;\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create enhanced interface\n",
    "def create_enhanced_black_interface():\n",
    "    \"\"\"Create a clean, simple black-themed interface with enhanced textbox\"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=custom_css, title=\"PersonalRAG\") as interface:\n",
    "        \n",
    "        # Header\n",
    "        gr.HTML(\"\"\"\n",
    "        <div class=\"header\">\n",
    "            <h1>PersonalRAG</h1>\n",
    "            <p>Your Personal Knowledge Assistant</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Main Chat Area\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                # Chat interface\n",
    "                chatbot = gr.Chatbot(\n",
    "                    height=600,\n",
    "                    container=True,\n",
    "                    bubble_full_width=False,\n",
    "                    show_label=False,\n",
    "                    elem_classes=[\"chatbot-clean\"]\n",
    "                )\n",
    "                \n",
    "                # Enhanced Input area with better styling\n",
    "                with gr.Row(elem_classes=\"input-row\"):\n",
    "                    msg = gr.Textbox(\n",
    "                        placeholder=\"Ask me anything about your documents, projects, or work experience...\",\n",
    "                        lines=2,\n",
    "                        scale=4,\n",
    "                        elem_classes=\"input-container\",\n",
    "                        show_label=False,\n",
    "                        container=False\n",
    "                    )\n",
    "                    submit_btn = gr.Button(\"Send\", elem_classes=\"btn-primary\", scale=1)\n",
    "                \n",
    "                # Control buttons\n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.Button(\"Clear Chat\", elem_classes=\"btn-secondary\", size=\"sm\")\n",
    "        \n",
    "        # Event handlers\n",
    "        \n",
    "        def handle_message(message, history):\n",
    "            \"\"\"Handle user messages\"\"\"\n",
    "            if not message.strip():\n",
    "                return history, \"\"\n",
    "            \n",
    "            # Get AI response\n",
    "            try:\n",
    "                response_messages = chat_messages(message, history)\n",
    "                response = response_messages[-1][\"content\"] if response_messages else \"Sorry, I couldn't generate a response.\"\n",
    "                history.append((message, response))\n",
    "            except Exception as e:\n",
    "                history.append((message, f\"Error: {str(e)}\"))\n",
    "            \n",
    "            return history, \"\"\n",
    "        \n",
    "        def clear_chat():\n",
    "            \"\"\"Clear the chat history\"\"\"\n",
    "            return []\n",
    "        \n",
    "        # Connect event handlers\n",
    "        msg.submit(handle_message, [msg, chatbot], [chatbot, msg])\n",
    "        submit_btn.click(handle_message, [msg, chatbot], [chatbot, msg])\n",
    "        \n",
    "        clear_btn.click(clear_chat, outputs=chatbot)\n",
    "        \n",
    "        # Add initial greeting\n",
    "        interface.load(\n",
    "            lambda: [(\"\", \"üëã Welcome to PersonalRAG! I'm here to help you explore your knowledge base. What would you like to know?\")],\n",
    "            outputs=chatbot\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and launch the enhanced interface\n",
    "interface = create_enhanced_black_interface()\n",
    "interface.launch(\n",
    "    inbrowser=True,\n",
    "    share=False,\n",
    "    show_error=True,\n",
    "    quiet=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95efd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
