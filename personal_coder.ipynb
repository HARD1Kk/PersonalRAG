{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4687ab22",
   "metadata": {},
   "source": [
    "# PersonalRAG \n",
    "\n",
    "A streamlined RAG system for your personal documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064630e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\virt_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "\n",
    "# PDF processing\n",
    "import pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51963c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment OK\n",
      "‚úÖ Embeddings and LLM initialized\n"
     ]
    }
   ],
   "source": [
    "# Complete RAG System Setup\n",
    "# =========================\n",
    "\n",
    "# Configuration\n",
    "MODEL = 'gpt-5-nano'\n",
    "db_name = 'vector_db'\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Validate environment\n",
    "required_vars = [\n",
    "    'AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_API_KEY',\n",
    "    'AZURE_OPENAI_API_VERSION',\n",
    "    'AZURE_OPENAI_EMBEDDING_DEPLOYMENT',\n",
    "    \n",
    "    \n",
    "    'AZURE_CHATOPENAI_DEPLOYMENT',\n",
    "    'AZURE_CHATOPENAI_ENDPOINT', 'AZURE_CHATOPENAI_API_KEY',\n",
    "    'AZURE_CHATOPENAI_API_VERSION'\n",
    "]\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing: {missing}\")\n",
    "    env_ok = False\n",
    "else:\n",
    "    print(\"‚úÖ Environment OK\")\n",
    "    env_ok = True\n",
    "\n",
    "# Initialize embeddings and LLM\n",
    "if env_ok:\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    )\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.getenv('AZURE_CHATOPENAI_DEPLOYMENT'),\n",
    "        azure_endpoint=os.getenv('AZURE_CHATOPENAI_ENDPOINT'),\n",
    "        api_key=os.getenv('AZURE_CHATOPENAI_API_KEY'),\n",
    "        api_version=os.getenv('AZURE_CHATOPENAI_API_VERSION'),\n",
    "    )\n",
    "    print(\"‚úÖ Embeddings and LLM initialized\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize - check environment variables\")\n",
    "    embeddings = None\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbddcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF processing available (pdfplumber)\n",
      "üìÑ Loaded 31 documents\n",
      "üìù Created 96 chunks\n"
     ]
    }
   ],
   "source": [
    "# Load and Process Documents\n",
    "# ==========================\n",
    "\n",
    "# Check PDF processing availability\n",
    "try:\n",
    "    import pdfplumber\n",
    "    PDF_AVAILABLE = True\n",
    "    print(\"‚úÖ PDF processing available (pdfplumber)\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        PDF_AVAILABLE = True\n",
    "        print(\"‚úÖ PDF processing available (PyPDF2)\")\n",
    "    except ImportError:\n",
    "        PDF_AVAILABLE = False\n",
    "        print(\"‚ö†Ô∏è PDF processing not available - install pdfplumber or PyPDF2\")\n",
    "\n",
    "# Auto-convert PDFs to markdown\n",
    "for root, dirs, files in os.walk(\"my-knowledge-worker-data\"):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(root, file)\n",
    "            md_path = pdf_path.rsplit('.', 1)[0] + '.md'\n",
    "            \n",
    "            if not os.path.exists(md_path):\n",
    "                try:\n",
    "                    with pdfplumber.open(pdf_path) as pdf:\n",
    "                        text = \"\\n\\n\".join([p.extract_text() or \"\" for p in pdf.pages])\n",
    "                    if text.strip():\n",
    "                        with open(md_path, 'w', encoding='utf-8') as f:\n",
    "                            f.write(f\"# {os.path.splitext(file)[0]}\\n\\n{text}\")\n",
    "                        print(f\"‚úÖ Converted: {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error: {file} - {e}\")\n",
    "\n",
    "def load_all_documents():\n",
    "    \"\"\"Load all markdown files from my-knowledge-worker-data\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for folder in glob.glob(\"my-knowledge-worker-data/*\"):\n",
    "        doc_type = os.path.basename(folder)\n",
    "        loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "        folder_docs = loader.load()\n",
    "        \n",
    "        for doc in folder_docs:\n",
    "            doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.extend(folder_docs)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Load documents\n",
    "documents = load_all_documents()\n",
    "print(f\"üìÑ Loaded {len(documents)} documents\")\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"üìù Created {len(chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34507f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded existing database (83 documents)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Smart vector database initialization\n",
    "if os.path.exists(db_name):\n",
    "    try:\n",
    "        vectorstore = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "        print(f\"‚úÖ Loaded existing database ({vectorstore._collection.count()} documents)\")\n",
    "    except:\n",
    "        shutil.rmtree(db_name)\n",
    "        vectorstore = None\n",
    "else:\n",
    "    vectorstore = None\n",
    "\n",
    "# To force rebuild: shutil.rmtree(db_name) if os.path.exists(db_name) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38d2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector database if needed\n",
    "if vectorstore is None:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks, \n",
    "        embedding=embeddings, \n",
    "        persist_directory=db_name\n",
    "    )\n",
    "    print(f\"‚úÖ Created new database ({vectorstore._collection.count()} documents)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34527063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database will be stored as: vector_db\n"
     ]
    }
   ],
   "source": [
    "# Configuration Settings\n",
    "MODEL = 'gpt-5-nano'\n",
    "\n",
    "# Vector Database Configuration\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Option 1: Simple name (current approach)\n",
    "db_name = 'vector_db'\n",
    "\n",
    "# Option 2: Timestamped database (uncomment to use)\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# db_name = f'vector_db_{timestamp}'\n",
    "\n",
    "# Option 3: Environment variable with fallback (uncomment to use)\n",
    "# db_name = os.getenv('VECTOR_DB_NAME', 'vector_db')\n",
    "\n",
    "# Option 4: Full path configuration (uncomment to use)\n",
    "# db_name = os.path.join('data', 'vector_databases', 'personal_knowledge_db')\n",
    "\n",
    "print(f\"Vector database will be stored as: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf44f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126a77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"my-knowledge-worker-data/*\")\n",
    "\n",
    "\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "    # Adds a 'doc_type' field to the document's metadata and returns the modified document\n",
    "\n",
    "\n",
    "text_loader_kwargs = {\"encoding\": \"utf-8\"}\n",
    "\n",
    "\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader= DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    temp_docs = loader.load()\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b265a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 88\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9416245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: {'projects', 'documents'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document types found: {set([doc.metadata['doc_type'] for doc in documents])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b1f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternative Embeddings Options\n",
    "# ================================\n",
    "\n",
    "# you can use these alternatives:\n",
    "\n",
    "# Option 1: HuggingFace Embeddings (Free, Local)\n",
    "# Uncomment the lines below to use HuggingFace embeddings instead:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Option 2: OpenAI Embeddings (if you have OpenAI API key)\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=\"your-openai-api-key\")\n",
    "\n",
    "# Option 3: Azure OpenAI Embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "# Usage Instructions:\n",
    "# 1. If Azure OpenAI embeddings failed, uncomment the HuggingFace lines above\n",
    "# 2. Or call: embeddings = get_alternative_embeddings()\n",
    "# 3. Make sure to install: pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073b2b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 1,536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42fc587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00539062, -0.00995838,  0.01023466, ..., -0.00820455,\n",
       "       -0.00697327, -0.00131612], shape=(1536,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e929534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14724\\3065617617.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb559481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom prompt template applied to conversation chain\n"
     ]
    }
   ],
   "source": [
    "# Custom Prompt Template for Better Responses\n",
    "# ===========================================\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a custom prompt template to prevent generic \"Option 1/Option 2\" responses\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are my personal AI assistant. Your task is to answer questions or summarize information using only my personal documents, code projects, notes, and emails provided as context. \n",
    "Never invent information beyond what is retrieved. Always specify source filenames in your answers. \n",
    "Be brief and focused; use markdown for readability and code blocks where appropriate.\n",
    "Reply in the style and language I use.\n",
    "If you cannot find an answer, admit it clearly.\n",
    "\n",
    "Context: {context}\n",
    "Chat History: {chat_history}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"chat_history\", \"question\"]\n",
    ")\n",
    "\n",
    "# Update the conversation chain with the custom prompt\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": qa_prompt}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Custom prompt template applied to conversation chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "151377ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Here‚Äôs a concise summary of your work experience based on your documents.\n",
      "\n",
      "- Full Stack Engineer (MERN stack)\n",
      "  - Built production-grade web apps with secure RESTful APIs (Node.js/Express), JWT authentication, and CRUD operations.\n",
      "  - Frontend/UI with React, EJS templating, and Tailwind CSS; deployed on Render, Vercel, and Railway.\n",
      "  - Emphasizes clean, modular code and robust API testing/documentation (Postman).\n",
      "\n",
      "  Source: Portfolio-2025\n",
      "\n",
      "- AI, ML, and RAG specialist\n",
      "  - Developed ML models (classification/regression) and NLP tasks (SER, speech processing) using TensorFlow, Keras, Scikit-learn, PyTorch.\n",
      "  - Built Retrieval-Augmented Generation (RAG) pipelines with ChromaDB and LangChain; integrated OpenAI and Gemini APIs; local embeddings for personal knowledge assistants.\n",
      "  - Focus on multimodal AI and dataset generation workflows.\n",
      "\n",
      "  Sources: Portfolio-2025; llm_engineering\n",
      "\n",
      "- Speech & NLP\n",
      "  - Projects leveraging Web Speech API for voice recognition and speech synthesis; built conversational agents with custom command handling.\n",
      "  - SER and emotion detection from audio; TTS/STT integration; NLP tooling (NLTK).\n",
      "\n",
      "  Sources: Portfolio-2025; llm_engineering\n",
      "\n",
      "- Data Science & Analytics\n",
      "  - Data cleaning, wrangling, EDA, and visualization (Matplotlib, Seaborn); analytical reporting and dashboards.\n",
      "\n",
      "  Source: Portfolio-2025\n",
      "\n",
      "- Mobile & React Native development\n",
      "  - Reusable React Native components with Expo; NativeWind for styling; TS-based codebase; navigation and animations (Reanimated).\n",
      "  - Real estate app (ReState-Networks) with authentication, map integration, favorites, and responsive UI.\n",
      "\n",
      "  Sources: ReState-Networks - Mobile Application; Portfolio-2025\n",
      "\n",
      "- Notable projects (examples across stacks)\n",
      "  - GenG Virtual Assistant: voice-driven assistant with Web Speech API, JS/Node, multi-tasking, customizable responses.\n",
      "  - Todo Buddy: web app (EJS/Node/PostgreSQL) for managing todos with authentication and secure DB integration.\n",
      "  - Books Notes: Node/Express with PostgreSQL for managing a book collection; deployment and environment configuration guidance.\n",
      "  - Trek Mark: PostgreSQL/Node-based travel-tracking app with country visitation counts.\n",
      "  - myDrumKit: (contextual project in portfolio)\n",
      "  - Weather/Movies-related tooling and integrations (examples of API usage and deployment).\n",
      "\n",
      "  Sources: llm_engineering; Todo Buddy; Trek Mark; Portfolio-2025\n",
      "\n",
      "- Tools, deployment, and collaboration\n",
      "  - Git/GitHub, Postman for API testing; environment variables and configuration guidance.\n",
      "  - Deployment on cloud/platforms (Render, Vercel, Railway, Netlify).\n",
      "\n",
      "  Sources: Portfolio-2025; Todo Buddy\n",
      "\n",
      "Sources\n",
      "- Portfolio-2025\n",
      "- llm_engineering\n",
      "- ReState-Networks - Mobile Application\n",
      "- Todo Buddy\n",
      "- Trek Mark\n",
      "- Books Notes\n",
      "- GenG Virtual Assistant (within llm_engineering)\n"
     ]
    }
   ],
   "source": [
    "query = \"what is my work experience\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc902a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_greeting(message):\n",
    "    \"\"\"Check if the message is a greeting\"\"\"\n",
    "    greetings = [\n",
    "        'hi', 'hello', 'hey', 'good morning', 'good afternoon', 'good evening',\n",
    "        'greetings', 'howdy', 'sup', 'what\\'s up', 'yo', 'good day',\n",
    "        'hi there', 'hello there', 'hey there', 'good to see you'\n",
    "    ]\n",
    "    \n",
    "    message_lower = message.lower().strip()\n",
    "    \n",
    "    # Check for exact matches\n",
    "    if message_lower in greetings:\n",
    "        return True\n",
    "    \n",
    "    # Check if message starts with greeting\n",
    "    for greeting in greetings:\n",
    "        if message_lower.startswith(greeting):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_greeting_response():\n",
    "    \"\"\"Get a friendly greeting response\"\"\"\n",
    "    greetings = [\n",
    "        \"Hello! üëã I'm PersonalRAG, your AI knowledge assistant. I'm here to help you find information from your documents, projects, and work experience. What would you like to know?\",\n",
    "        \"Hi there! ü§ñ Welcome to PersonalRAG. I can help you search through your knowledge base and answer questions about your work, projects, and documents. How can I assist you today?\",\n",
    "        \"Hey! üòä Great to see you! I'm PersonalRAG, ready to help you explore your personal knowledge base. Feel free to ask me anything about your documents or projects!\",\n",
    "        \"Hello! üåü I'm PersonalRAG, your intelligent knowledge assistant. I'm here to help you discover insights from your documents and answer questions about your work experience. What can I help you with?\"\n",
    "    ]\n",
    "    \n",
    "    import random\n",
    "    return random.choice(greetings)\n",
    "\n",
    "def chat(question, history):\n",
    "    \"\"\"Enhanced chat function with greeting detection\"\"\"\n",
    "    try:\n",
    "        # Check for greetings first\n",
    "        if is_greeting(question):\n",
    "            return get_greeting_response()\n",
    "        \n",
    "        # Get response from conversation chain\n",
    "        result = conversation_chain.invoke({\"question\": question})\n",
    "        return result[\"answer\"]\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Sorry, I encountered an error: {str(e)}\\n\\nPlease try again or rephrase your question.\"\n",
    "\n",
    "def chat_messages(message, history):\n",
    "    \"\"\"Chat function that returns messages in the correct format with greeting support\"\"\"\n",
    "    try:\n",
    "        # Check for greetings first\n",
    "        if is_greeting(message):\n",
    "            greeting_response = get_greeting_response()\n",
    "            return history + [{\"role\": \"assistant\", \"content\": greeting_response}]\n",
    "        \n",
    "        # Get response from conversation chain\n",
    "        result = conversation_chain.invoke({\"question\": message})\n",
    "        response = result[\"answer\"]\n",
    "        \n",
    "        # Return in the correct format for messages\n",
    "        return history + [{\"role\": \"assistant\", \"content\": response}]\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Sorry, I encountered an error: {str(e)}\\n\\nPlease try again or rephrase your question.\"\n",
    "        return history + [{\"role\": \"assistant\", \"content\": error_msg}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88faae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
